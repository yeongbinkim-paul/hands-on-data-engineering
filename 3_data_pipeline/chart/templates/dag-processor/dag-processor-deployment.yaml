################################
## Airflow Dag Processor Deployment
#################################
kind: Deployment
apiVersion: apps/v1
metadata:
  name: {{ .Chart.Name }}-dag-processor-{{ .Values.env }}
  namespace: {{ .Release.Namespace | quote }}
  labels:
{{- with .Values.labels }}
{{ toYaml . | indent 4 }}
{{- end }}
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: airflow
      component: dag-processor
      release: {{ .Chart.Name | quote }}
  strategy:
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 50%
  template:
    metadata:
      labels:
        tier: airflow
        component: dag-processor
        release: {{ .Chart.Name | quote }}
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  component: dag-processor
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        []
      topologySpreadConstraints:
        []
      terminationGracePeriodSeconds: 200
      restartPolicy: Always
      serviceAccountName: {{ .Chart.Name }}-{{ .Values.env }}
      securityContext:
        runAsUser: 50000
        fsGroup: 0
        fsGroupChangePolicy: "OnRootMismatch"
      initContainers:
        - name: wait-for-airflow-migrations
          resources:
            {}
          image: {{ template "airflow_image" . }}
          imagePullPolicy: Never
          args:
            - airflow
            - db
            - check-migrations
            - --migration-wait-timeout=60
          envFrom:
            []
          env:
            {{- include "standard_airflow_environment" . | indent 10 }}
      {{- include "git_sync_container" (dict "Values" .Values "is_init" "true") | nindent 8 }}
      containers:
        - name: update-dag
          image: alpine:latest
          imagePullPolicy: Always
          resources:
            {{- toYaml .Values.updateDag.resources | nindent 12 }}
          command:
            - /scripts/update-dag.sh
          securityContext:
            runAsUser: 50000
          volumeMounts:
            - name: {{ .Chart.Name }}-update-dag
              mountPath: /scripts
            - name: dag-data
              mountPath: /opt/airflow/data-pipeline
        - name: dag-processor
          image: {{ template "airflow_image" . }}
          imagePullPolicy: Never
          args:
            - bash
            - -c
            - exec airflow dag-processor
          resources:
            {{- toYaml .Values.dagProcessor.resources | nindent 12 }}
          volumeMounts:
            - name: logs
              mountPath: /opt/airflow/logs
            - name: config
              mountPath: /opt/airflow/pod_templates/pod_template_file.yaml
              subPath: pod_template_file.yaml
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/airflow.cfg"
              subPath: airflow.cfg
              readOnly: true
            - name: config
              mountPath: "/opt/airflow/config/airflow_local_settings.py"
              subPath: airflow_local_settings.py
              readOnly: true
            - name: dag-data
              mountPath: /opt/airflow/data-pipeline
          envFrom:
            []
          env:
            {{- include "standard_airflow_environment" . | nindent 10 }}
            {{- include "extra_airflow_environment" . | nindent 10 }}
            - name: AIRFLOW__METRICS__STATSD_PORT
              value: "8125"
            - name: AIRFLOW__METRICS__STATSD_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
          livenessProbe:
            initialDelaySeconds: 10
            timeoutSeconds: 20
            failureThreshold: 10
            periodSeconds: 200
            exec:
              command:
                  - sh
                  - -c
                  - |
                    CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
                    airflow jobs check
      volumes:
        - name: dag-data
          persistentVolumeClaim:
            claimName: "dag-data-{{ .Values.env }}-pvc"
        - name: logs
          emptyDir: {}
        - name: config
          configMap:
            name: {{ .Chart.Name }}-airflow-config-{{ .Values.env }}
        - name: {{ .Chart.Name }}-update-dag
          configMap:
            name: {{ .Chart.Name }}-update-dag-{{ .Values.env }}
            defaultMode: 0755
        {{- include "git_sync_ssh_key_volume" . | indent 8 }}
